# 线代(torch)

> 基本数学对象、算术和运算
> 

## 标量，向量，矩阵……

- 基本操作
    
    标量 `x = torch.tensor(3.0)`
    
    向量`x = torch.arange(4)`
    
    矩阵`A = torch.arange(20).reshape(5, 4)`，转置操作：`A.T`
    

## 张量

> 描述具有任意数量轴的n维数组的通用方法
> 
- `X = torch.arange(24).reshape(2, 3, 4)`
    
    ```
    tensor([[[ 0,  1,  2,  3],
             [ 4,  5,  6,  7],
             [ 8,  9, 10, 11]],
    
            [[12, 13, 14, 15],
             [16, 17, 18, 19],
             [20, 21, 22, 23]]])
    ```
    
    ### 基本运算
    
    ```python
    A = torch.arange(20, dtype=torch.float32).reshape(5, 4)
    B = A.clone()# 通过分配新内存，将A的一个副本分配给B
    
    A, A + B
    ```
    
    $$
    Hadamard\ Product:A\odot B
    $$
    
    code: `A * B`
    

### !降维

- 求和
    
    1维
    
    长度为d 的向量求出总和
    
    $$
    \sum_{i=1}^{d}x_i
    $$
    
    ```python
    x = torch.arange(4, dtype=torch.float32)
    x, x.sum()
    ```
    
    多维：
    
    $$
    \sum_{i=1}^{m}\sum^{n}_{m}a_{ij}
    $$
    
    `A.shape, A.sum()`
    
- 沿轴降维度
    
    ```python
    A_sum_axis0 = A.sum(axis=0)
    A_sum_axis0, A_sum_axis0.shape
    ```
    
    axis=0， 沿着轴0,1,2（x/y/z）
    
    axis=[0,1] = 沿着row,coloumn求和，等价 A.sum (在二维的情况下)
    
    计算平均值；`A.mean(), A.sum() / A.numel()`
    
    同样可以指定轴
    
    ## 非降维求和
    
    `A.cumsum(axis=0)`
    
    ## Dot Product
    
    ```python
    y = torch.ones(4, dtype = torch.float32)
    x, y, torch.dot(x, y)
    ```
    

## matrix-vector product

$$
A \in \mathbb{R}^{m \times n} \newline X\in \mathbb{R}^n
$$

可以把乘法 A*X  理解为R^n→R^m的向量转换

可以使用矩阵-向量积来描述在给定前一层的值时， 求解神经网络每一层所需的复杂计算。

## norm(范数)

> 表示一个向量有多大 (不涉及维度，而是分量的大小。)
> 
- 范数三性质:
    
    缩放：
    
    $$
    f(ax) = |a|f(x)
    $$
    
    三角不等式
    
    $$
    f(x+y)\le f(x)+f(y)
    $$
    
    非负
    
    $$
    f(x)\geq 0
    $$
    
     最后一个性质要求范数最小为0，当且仅当向量全由0组成
    
    > 范数听起来很像距离的度量。 欧几里得距离和毕达哥拉斯定理中的非负性概念和三角不等式可能会给出一些启发。 事实上，欧几里得距离是一个L2范数
    -TextBook
    > 
    
    $$
    L_2范数：||x||_2= \sqrt{\sum_{i=1}^n}x^2_i \newline L_1范数：||x||_1 = \sum{|x_i|} \newline
    ||X||_p = \sqrt{\sum^n_{i=1}|x_i|^p}
    $$