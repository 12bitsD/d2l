# 线性回归

---

给定n维输入‘x’， 和n维权重‘w’，一个标量偏差

$$
X=[x_1,x_2,x_3....x_n]^T \newline
W = [w_1,w_2,...,w_n]^T\newline b
$$

输出y为：

$$
y=<W，X>+b
$$

![image.png](%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%20163a4fd6ce5080b98956fe9257415548/image.png)

箭头为权重

## 衡量预估的质量

比较预测输出和真实输出

损失平方：

$$
y：真实值，\hat{y}：估计值\newline  l(y,\hat{y})={1\over 2}(y-\hat{y})^2
$$

训练数据：

一系列数据点决定参数值（权重和偏差）

有了数据之后 求解模型：

- 参数学习 ：
    
    训练损失(损失函数)
    
    $$
    l(X,y,w,b)={1 \over 2n} \sum^n_{i=1}(y_i-<x_i,w>-b)^2 ={1\over 2n}||y-X*w-b||^2
    $$
    

最小化损失函数，选取w*和b* 来学习参数 

$$
w*,b*=\arg \min_{w,b} \ l(X,y,w,b)
$$

显示解：

偏差加入权重 X ← [X,1], w ←[w,b]

预测为 X*w

$$
{\partial l(X,y,w)\over \partial w}={1\over n}(y-X*w)^TX
$$

损失函数是 凸函数，所以最优解，可以是：

$$
{\partial l(X,y,w)\over \partial w}=0\newline w^*=(X^TX)^{-1}Xy
$$

总：

线性回归是对n维输入的加权，再加上偏差

平方损失可以衡量预测值和真实值的差异

线性回归有显示解

线性回归可以看作为单层的神经网络