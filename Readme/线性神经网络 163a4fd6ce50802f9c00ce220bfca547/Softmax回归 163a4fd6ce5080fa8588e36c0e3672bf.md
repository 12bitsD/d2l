# Softmax回归

> softmax使用梯度回归分类的模型
使用softmax操作子，得到每个类的预测probability
交叉熵做损失函数计算（预测值，真实值）的区别
> 

$$
y = [y_1,y_2,...,y_n]^T \newline y_i = 1 (if \ i=y)  ||\ 0 (otherwise)
$$

$$
o_y-o_i\geq \triangle (y,i)
$$

## Softmax模型

最大值就是预测值：

$$
\hat{y}=\argmax_i o_i
$$

$$
\hat{y}=softmax(o) \newline
\hat{y_i}= {\exp(o_i) \over \sum _k exp(o_k)}
$$

和更置信的识别正确类

### 输出是一个匹配的概率，（非负，和为1）

概率y,和y预测的区别作为损失

$$
\hat{y}中的第i个元素= o_i的指数，\newline 再除以所有的O_k做值。所有\hat{y_i}相加=1
$$

![image.png](Softmax%E5%9B%9E%E5%BD%92%20163a4fd6ce5080fa8588e36c0e3672bf/image.png)

## 交叉熵损失

> 交叉熵损失函数用于分类问题，衡量模型预测的概率分布与真实标签之间的差异
> 

交叉熵函数(cross entropy):

衡量两个概率的区别

$$
H(p,q) = \sum_i-p_ilog(q_i)
$$

用交叉熵做 损失函数

$$
l(y,\hat{y})=-log \hat{y}_y
$$

梯度 = 真实概率（y）和预测概率（y hat）的区别

$$
\partial _{o_i}l(y,\hat{y})= softmax (o)_i - y_i
$$