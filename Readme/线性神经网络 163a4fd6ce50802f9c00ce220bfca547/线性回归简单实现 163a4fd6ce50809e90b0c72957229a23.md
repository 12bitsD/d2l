# 线性回归简单实现

用pytorch nn模组

## 构筑PyTorch 数据迭代器

> 用feature 和lable打包了一个数据集
根据 batch_size 和is_train构造DataLoader对象
> 

```python
def load_array(data_arrays, batch_size, is_train=True):  #@save
    """构造一个PyTorch数据迭代器"""
    dataset = data.TensorDataset(*data_arrays)
    return data.DataLoader(dataset, batch_size, shuffle=is_train)

batch_size = 10
data_iter = load_array((features, labels), batch_size)
```

 `dataset = data.TensorDataset(*data_arrays)`将多个张量打包成一个数据集

例如，如果 `data_arrays = (features, labels)`，那么 `TensorDataset` 会将 `features` 和 `labels` 打包成一个数据集，每个样本由一对 `(feature, label)` 组成

 `return data.DataLoader(dataset, batch_size, shuffle=is_train)`

• `data.DataLoader` 是一个 PyTorch 提供的类，用于从数据集中按批次提取数据。

- `dataset`: 输入的数据集（这里是 `TensorDataset`）。
- `batch_size`: 每个批次的大小。
- `shuffle`: 是否打乱数据顺序。如果是 `True`，数据会随机打乱；如果是 `False`，数据顺序保持不变。

## 定义模型

```python
from torch import nn

net = nn.Sequential(nn.Linear(2,1))

```

`nn.Linear(x,y)` 线性模型（X*w）+b

- ?为什么需要指定输入输出维度？
    - 1 确保矩阵能正确运算
        - **输入矩阵** input 的形状为 (batch_size,in_features)。
        - **权重矩阵** weight 的形状为 (out_features,in_features)
        - **矩阵乘法** input⋅weightTinput⋅weight*T* 的维度匹配要求：
            - input 的列数（`in_features`）必须等于 weightT 的行数（`in_features`）。
            - 乘法的结果是一个形状为 (batch_size,out_features) 的矩阵。
    

linear(2,1)

$$
linear(2,1); 根据两个输入（x_1,x_2）预测一个输出（y）
$$

## 初始化模型参数

net[0]→linear() 第一层

```python
net[0].weight.data.normal_(0, 0.01)
net[0].bias.data.fill_(0)
```

通过weight 访问权重，用normal替换data值.

## 损失函数

MSE losfunction

```python
loss =nn.MSELoss()
```

## 优化算法：

```python
trainer = torch.optim.SGD(net.parameters(), lr=0.03)
```

SGD实例

```python
num_epochs=3
for epoch in range(num_epochs):
	for x,y in data_iter:
		trainer.zero_grad()
		l = loss(net(x),y)
		l.backward()
		trainer.step()
		
	l= loss(net(features),labels)
	print(f'epoch{epoch+1}，loos{l:f}')
```

trainer.step - 计算出梯度后，更新模型